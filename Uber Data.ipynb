{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06cc601-f968-475e-8f50-725a92b1924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1758475-6922-4de7-ad60-38d7c895fce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists. Proceeding to load files...\n",
      "\n",
      "✅ Loaded other-American_B01362.csv successfully with 91712 rows and 6 columns.\n",
      "✅ Loaded other-Carmel_B00256.csv successfully with 256519 rows and 4 columns.\n",
      "✅ Loaded other-Dial7_B00887.csv successfully with 194992 rows and 6 columns.\n",
      "✅ Loaded other-Diplo_B01196.csv successfully with 98550 rows and 3 columns.\n",
      "✅ Loaded other-Federal_02216.csv successfully with 276 rows and 7 columns.\n",
      "✅ Loaded other-FHV-services_jan-aug-2015.csv successfully with 26181 rows and 5 columns.\n",
      "✅ Loaded other-Firstclass_B01536.csv successfully with 166769 rows and 3 columns.\n",
      "✅ Loaded other-Highclass_B01717.csv successfully with 151925 rows and 3 columns.\n",
      "✅ Loaded other-Lyft_B02510.csv successfully with 267701 rows and 4 columns.\n",
      "✅ Loaded other-Prestige_B01338.csv successfully with 320641 rows and 3 columns.\n",
      "✅ Loaded other-Skyline_B00111.csv successfully with 127696 rows and 6 columns.\n",
      "✅ Loaded Uber-Jan-Feb-FOIL.csv successfully with 354 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-apr14.csv successfully with 564516 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-aug14.csv successfully with 829275 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-janjune-15.csv successfully with 14270479 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-janjune-15_sample.csv successfully with 100000 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-jul14.csv successfully with 796121 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-jun14.csv successfully with 663844 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-may14.csv successfully with 652435 rows and 4 columns.\n",
      "✅ Loaded uber-raw-data-sep14.csv successfully with 1028136 rows and 4 columns.\n",
      "\n",
      "All CSV files loaded successfully:\n",
      "['other-American_B01362.csv', 'other-Carmel_B00256.csv', 'other-Dial7_B00887.csv', 'other-Diplo_B01196.csv', 'other-Federal_02216.csv', 'other-FHV-services_jan-aug-2015.csv', 'other-Firstclass_B01536.csv', 'other-Highclass_B01717.csv', 'other-Lyft_B02510.csv', 'other-Prestige_B01338.csv', 'other-Skyline_B00111.csv', 'Uber-Jan-Feb-FOIL.csv', 'uber-raw-data-apr14.csv', 'uber-raw-data-aug14.csv', 'uber-raw-data-janjune-15.csv', 'uber-raw-data-janjune-15_sample.csv', 'uber-raw-data-jul14.csv', 'uber-raw-data-jun14.csv', 'uber-raw-data-may14.csv', 'uber-raw-data-sep14.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "directory_path = r\"F:\\INTERNSHIP\\Mysql\\uber\\\\\"\n",
    "\n",
    "if os.path.exists(directory_path):\n",
    "    print(\"Directory exists. Proceeding to load files...\\n\")\n",
    "else:\n",
    "    print(\"Directory does NOT exist. Please check the path.\")\n",
    "    raise Exception(\"Invalid file path\")\n",
    "\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='latin1')\n",
    "        dataframes[file] = df\n",
    "        print(f\"✅ Loaded {file} successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading {file}: {e}\")\n",
    "\n",
    "print(\"\\nAll CSV files loaded successfully:\")\n",
    "print(list(dataframes.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab49949-d111-46ca-aa07-894768e6f994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-American_B01362.csv successfully with 91124 rows and 3 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Carmel_B00256.csv successfully with 247553 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Dial7_B00887.csv successfully with 192746 rows and 6 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Diplo_B01196.csv successfully with 97470 rows and 3 columns.\n",
      "✅ Cleaned other-Federal_02216.csv successfully with 276 rows and 7 columns.\n",
      "✅ Cleaned other-FHV-services_jan-aug-2015.csv successfully with 26181 rows and 5 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Firstclass_B01536.csv successfully with 165523 rows and 3 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Highclass_B01717.csv successfully with 151235 rows and 3 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('Unknown', inplace=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Lyft_B02510.csv successfully with 267700 rows and 3 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Prestige_B01338.csv successfully with 318546 rows and 3 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned other-Skyline_B00111.csv successfully with 122843 rows and 4 columns.\n",
      "✅ Cleaned Uber-Jan-Feb-FOIL.csv successfully with 354 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-apr14.csv successfully with 556767 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-aug14.csv successfully with 813393 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-janjune-15.csv successfully with 13372254 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-janjune-15_sample.csv successfully with 99946 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-jul14.csv successfully with 781969 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-jun14.csv successfully with 653158 rows and 4 columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned uber-raw-data-may14.csv successfully with 642360 rows and 4 columns.\n",
      "✅ Cleaned uber-raw-data-sep14.csv successfully with 1004099 rows and 4 columns.\n",
      "\n",
      "All CSV files cleaned successfully:\n",
      "['other-American_B01362.csv', 'other-Carmel_B00256.csv', 'other-Dial7_B00887.csv', 'other-Diplo_B01196.csv', 'other-Federal_02216.csv', 'other-FHV-services_jan-aug-2015.csv', 'other-Firstclass_B01536.csv', 'other-Highclass_B01717.csv', 'other-Lyft_B02510.csv', 'other-Prestige_B01338.csv', 'other-Skyline_B00111.csv', 'Uber-Jan-Feb-FOIL.csv', 'uber-raw-data-apr14.csv', 'uber-raw-data-aug14.csv', 'uber-raw-data-janjune-15.csv', 'uber-raw-data-janjune-15_sample.csv', 'uber-raw-data-jul14.csv', 'uber-raw-data-jun14.csv', 'uber-raw-data-may14.csv', 'uber-raw-data-sep14.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_24032\\3603395511.py:24: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory_path = r\"F:\\INTERNSHIP\\Mysql\\uber\\\\\"\n",
    "\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    missing_threshold = 0.5\n",
    "    df.dropna(thresh=len(df) * missing_threshold, axis=1, inplace=True)\n",
    "    \n",
    "    df.fillna('Unknown', inplace=True)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = pd.to_numeric(df[column], errors='ignore')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return df\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='latin1')\n",
    "        cleaned_df = clean_dataframe(df)\n",
    "        dataframes[file] = cleaned_df\n",
    "        print(f\"✅ Cleaned {file} successfully with {cleaned_df.shape[0]} rows and {cleaned_df.shape[1]} columns.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error loading {file}: {e}\")\n",
    "\n",
    "print(\"\\nAll CSV files cleaned successfully:\")\n",
    "print(list(dataframes.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba27b5f-8253-4d45-a658-910513ab98e5",
   "metadata": {},
   "source": [
    "# 1. Analyze Which Month Has Maximum Uber Pickups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0c588b-56e5-4a25-89d9-d073be641783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month with maximum pickups: 9 with 1028136 pickups.\n"
     ]
    }
   ],
   "source": [
    "combined_data['month'] = combined_data['date/time'].dt.month\n",
    "\n",
    "max_month = combined_data['month'].value_counts().idxmax()\n",
    "max_month_count = combined_data['month'].value_counts().max()\n",
    "print(f\"Month with maximum pickups: {max_month} with {max_month_count} pickups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9cd98-4d85-45cf-b1da-472dc49c82ea",
   "metadata": {},
   "source": [
    "# 2. Analyze Hourly Rush in New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4166d39-db63-4529-922f-f74aea1898aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most active hour: 17:00 with 336190 pickups.\n"
     ]
    }
   ],
   "source": [
    "combined_data['hour'] = combined_data['date/time'].dt.hour\n",
    "\n",
    "peak_hour = combined_data['hour'].value_counts().idxmax()\n",
    "peak_hour_count = combined_data['hour'].value_counts().max()\n",
    "print(f\"Most active hour: {peak_hour}:00 with {peak_hour_count} pickups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c856f76-5a39-4cf6-ad78-676b5abd3800",
   "metadata": {},
   "source": [
    "# 3. Most Active Uber Base Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "580527e5-dc74-4f9a-89b8-fadfc0e155f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Active Uber Base Number: B02617 with 1458853 pickups.\n"
     ]
    }
   ],
   "source": [
    "most_active_base = combined_data['base'].value_counts().idxmax()\n",
    "most_active_base_count = combined_data['base'].value_counts().max()\n",
    "print(f\"Most Active Uber Base Number: {most_active_base} with {most_active_base_count} pickups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde5456-d3eb-47c6-92de-8e0cbdb6caff",
   "metadata": {},
   "source": [
    "# 4.Removing uber-raw-data-janjune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28baffc0-73e4-4c0e-a025-a93d3398e692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Files (Row-wise):\n",
      "Uber-Jan-Feb-FOIL.csv\n",
      "uber-raw-data-apr14.csv\n",
      "uber-raw-data-aug14.csv\n",
      "uber-raw-data-janjune-15.csv\n",
      "uber-raw-data-janjune-15_sample.csv\n",
      "uber-raw-data-jul14.csv\n",
      "uber-raw-data-jun14.csv\n",
      "uber-raw-data-may14.csv\n",
      "uber-raw-data-sep14.csv\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Updated file list after removal (Row-wise):\n",
      "other-American_B01362.csv\n",
      "other-Carmel_B00256.csv\n",
      "other-Dial7_B00887.csv\n",
      "other-Diplo_B01196.csv\n",
      "other-Federal_02216.csv\n",
      "other-FHV-services_jan-aug-2015.csv\n",
      "other-Firstclass_B01536.csv\n",
      "other-Highclass_B01717.csv\n",
      "other-Lyft_B02510.csv\n",
      "other-Prestige_B01338.csv\n",
      "other-Skyline_B00111.csv\n",
      "Uber-Jan-Feb-FOIL.csv\n",
      "uber-raw-data-apr14.csv\n",
      "uber-raw-data-aug14.csv\n",
      "uber-raw-data-janjune-15_sample.csv\n",
      "uber-raw-data-jul14.csv\n",
      "uber-raw-data-jun14.csv\n",
      "uber-raw-data-may14.csv\n",
      "uber-raw-data-sep14.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define your folder path\n",
    "folder_path = r\"F:\\INTERNSHIP\\Mysql\\uber\"\n",
    "\n",
    "# Collecting all file names from the folder\n",
    "all_files = os.listdir(folder_path)\n",
    "\n",
    "# Extracting the last 9 files using negative indexing\n",
    "Extract = all_files[-9:]\n",
    "\n",
    "print(\"Extracted Files (Row-wise):\")\n",
    "for file in Extract:\n",
    "    print(file)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Removing Jan_June Data file\n",
    "file_to_remove = \"uber-raw-data-janjune-15.csv\"\n",
    "\n",
    "if file_to_remove in all_files:\n",
    "    all_files.remove(file_to_remove)\n",
    "    print(\"Updated file list after removal (Row-wise):\")\n",
    "    for file in all_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(f\"'{file_to_remove}' not found in the list.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d35332-7131-4994-ac42-ac0fcbf830a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
